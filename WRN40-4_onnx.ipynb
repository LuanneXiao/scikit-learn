{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random;\n",
    "import math;\n",
    "from PIL import Image\n",
    "import torch.onnx as torch_onnx\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型选择之前预测正确率最高的WRN40-4（dropout=0.5)模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##WRN40-4 （dropout=0.5)模型\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) / 6\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv0 = nn.Conv2d(1,3,kernel_size=1,stride=1)   ##\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入已经训练好的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "cnn = WideResNet(40, 10, 4, 0.5)\n",
    "cnn.load_state_dict(torch.load('net_paramet_WRN_normalization.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入自定义图像，图像文件夹路径可更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 of 2 (C:/Users/15273/Desktop/figure\\fig1.jpg)\n",
      "Processing 2 of 2 (C:/Users/15273/Desktop/figure\\fig2.jpg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize(29),  #将图像的短边缩放成29个像素，长边按短边比例缩放\n",
    "    transforms.RandomCrop(28),  #随机裁剪成28*28\n",
    "    transforms.ToTensor(), \n",
    "     transforms.Normalize(mean=[.2861], std=[.3530])  #mean和std采用与训练WRN网络时相同的取值\n",
    "    ])\n",
    "def get_files(directory):\n",
    "    return [os.path.join(directory, f) for f in sorted(list(os.listdir(directory)))\n",
    "            if os.path.isfile(os.path.join(directory, f))]\n",
    "images = np.array([])\n",
    "file = get_files('C:/Users/15273/Desktop/figure')\n",
    "for i, item in enumerate(file):\n",
    "    print('Processing %i of %i (%s)' % (i+1, len(file), item))\n",
    "    image = transform(PIL.ImageOps.invert(Image.open(item).convert('L')))\n",
    "    images = np.append(images, image.numpy())        \n",
    "img = images.reshape(-1, 1, 28, 28)\n",
    "img = torch.from_numpy(img).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示输入的自定义图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAE8lJREFUeJzt3W2Q3WV5x/Hfdc4+5GmJCVloROIig1YqI+pKtbQVRBRxHKQdHdAqjkyjMzADHV+Y4Y2OHWd4oeh07NiJwiRYCqVFK23BNiA2ZbTIioBgiGCMZJO42UwENuRhs+dcfbGHdsl9/ck5u+ec3f+9389MZnevvf/n3Cd77ZV/zv1k7i4AQPlV5rsDAID2oKADQCYo6ACQCQo6AGSCgg4AmaCgA0AmKOgAkAkKOgBkYk4F3cwuMbPtZvaMmW1oV6eA+UZuo4xstitFzawq6ZeSLpY0KulhSVe6+y/a1z2g+8htlFXPHK49T9Iz7r5DkszsDkmXSSpM+jVr1vjQ0NAcnhIotnPnTu3fv9/a8FCLMrcnJ4+G8ecPHGj6MczSv/7wlrGFG8mim844HrddtWYwifX19Tfdh/nWbG7PpaCfJmnXjK9HJf3hK10wNDSkkZGROTwlUGx4eLhdD7Uoc3t056/C+L/9421psKAe9wRFsh4U3qlavaAXaVs/dixseWzySPpc9fhxP3L1Z5LYa4ZeV9CHhafZ3J7Le+jRvxbJT8PM1pvZiJmNjI+Pz+HpgK4ht1FKcynoo5JOn/H1ayTtOb6Ru29092F3Hx4cTP/bAyxA5DZKaS5vuTws6SwzO0PSbklXSPpoW3oFzK9Fmds7nnoyjN97Z/qWS9GdYE+1msQ8eBulpycuPbVaLb2+4N2ZY0HbSm9v2PZP33dpEivTWy7NmnVBd/cpM7tW0n9Iqkq6xd3jjABKhNxGWc3lDl3ufo+ke9rUF2DBILdRRqwUBYBMUNABIBMUdADIxJzeQweQj/1jY2E8uuurFKxZjGaeRKtCJ6eCdopXf/ZU0pkzRTx6fhW/ttxwhw4AmaCgA0AmKOgAkAkKOgBkgkFRYBGKBh/37km2q5EkHTo6mcR6KvG9YCUYLe3rSQc1j03GOyj29qRL9188fDhsa0Efop0dJWn37tEwnhvu0AEgExR0AMgEBR0AMkFBB4BMUNABIBPMcslcPTi7cWqqYIZBX18Siw79Rfl5cGrEC88/F7aNUqBWj5fY91TTHIqOD63V4tkodU9zs+g46WoLuTnxXHrQdb3g5IyKlfc+t7w9BwC8DAUdADJBQQeATFDQASATcxoUNbOdkiYk1SRNuftwOzq1OEVDP/GgT7Rs+3DB8ui/v/XbSWzPaLwM+trrrktiawbXhG1zl3tuR4PltSNxDlWDQcKiAcWp2lQSK1iNH/ernj5upWDwM9w7vRrvnX54YiJ9rmi0VlKlp7z3ue2Y5XKhu+9vw+MACw25jVIp7z9FAICXmWtBd0n/aWY/NbP17egQsECQ2yidub7lcr677zGzUyRtMbOn3H3rzAaNX4b1krRu3bo5Ph3QNeQ2SmdOd+juvqfxcZ+k70o6L2iz0d2H3X14cHBwLk8HdA25jTKa9R26mS2XVHH3icbn75X0xbb1rGR2PftsEvv1jh1x41q6vPn536VLkw8diZfoHzz4Ynr98y+Ebe+9594kVrT0/yNXXJHEFuMsl8WQ27VaunR/8ujRsG24FL7gVrDogInjWXAQRtFzRTNfJKkSHHARxSTp0MH096MezMiRJPWUd0eUufT8VEnfbez10SPpH9z9+23pFTC/yG2U0qwLurvvkPTmNvYFWBDIbZQV0xYBIBMUdADIRHnf/V9gnjvwuyQ2PjYWtj1pYHkS6+tLTztfc+qrw+uXrRhIY0uXhm3XnpY+xrf+bmPYdvtT25PY2W/6g7Atyq0WDAgeKdg+ItqWwgq2pQjvEIOmRUOnrey/H7UtGkCNBnyLlv6XGXfoAJAJCjoAZIKCDgCZoKADQCYo6ACQCWa5tMk556brUKJYt607YyiJje2NZ9/8+Ec/TmLve/8lYdtly5fNpVuYZ9FskNpUwVL4QPFklPQb0WyUWsEBGdHDFh1w0YroMAwv6EOZcYcOAJmgoANAJijoAJAJCjoAZIJB0cz19/cnsXee/86w7Zf++ktJ7CcP/SRs+64L35XEWlm2jXkW7VtesJd5Kz/XaPAxfMyCrQOiePGgaDAAW7DPerTZQHM9LRfu0AEgExR0AMgEBR0AMkFBB4BMnLCgm9ktZrbPzJ6YEVttZlvM7OnGx1Wd7SbQfuQ2ctPMLJdNkr4u6dYZsQ2S7nf3G81sQ+Prz7W/e+iE/iVLwvjkkfQQgK333Ru2fdvbzkliAytPnlvHum+TFmlux7NR5r4UPpqQEsWqlWp8fRArOLNCCma0FM2IiZf+5zfP5YR36O6+VdKB48KXSdrc+HyzpA+1uV9Ax5HbyM1s30M/1d33SlLj4ynt6xIwr8htlFbHB0XNbL2ZjZjZyPj4eKefDugachsLzWwL+piZrZWkxsd9RQ3dfaO7D7v78ODg4CyfDugachulNdul/3dLukrSjY2P32tbj9Bxfb29YfzkVSuS2HJ7IWz7y8d+lMTe9icfiJ/QSjU7dvHmdtGAYtS08CGa2w992cBJ4fWHJoJ8a2FHiXrRQGd+45+hZqYt3i7px5LeYGajZna1ppP9YjN7WtLFja+BUiG3kZsT3qG7+5UF37qozX0BuorcRm5K9X9hAEAxCjoAZIKCDgCZ4ICLRejgwefC+DmvT9fQVOtHwrb7Rn+VxOr1+NT4SrWvhd5hvlQLZpNEh060cpZJpZLeNy4fGAjbHj44kT6Xx09WOKMl0Ozsm7LjDh0AMkFBB4BMUNABIBMUdADIBIOimfNgzfOS6mTY9o1nrk1iY3t2h237+9J7gQy3l15cOjRIGA2KrjgpHhQ9MJb2oV6UV0G8aKDTgr3Tc8QdOgBkgoIOAJmgoANAJijoAJAJBkUz4QUn6Y7teTaJrRzoD9ue+fozk1hV8QDqwMDKJGbB4BfKo+jQ5FbGSsNBySC2dHm6937hYxZsiG7BqGiOBz+3gt9AAMgEBR0AMkFBB4BMUNABIBPNnCl6i5ntM7MnZsS+YGa7zezRxp9LO9tNoP3IbeSmmVkumyR9XdKtx8W/6u5fbnuPcELHJo8msf/Z+sOw7Q9/8IMk9vFP/UXYduicdyWxesG/+b1L0qXbZqX7D98mkdv/p5X9waMZJtOPkeZA9LhLlxXNcmlhSk3YhbhfHuwfkOOMmBP+Brr7VkkHutAXoKvIbeRmLrdU15rZ443/tq5qW4+A+Uduo5RmW9C/IelMSedK2ivpK0UNzWy9mY2Y2cj4+Pgsnw7oGnIbpTWrgu7uY+5ec/e6pG9KOu8V2m5092F3Hx4cHJxtP4GuILdRZrNa+m9ma919b+PLyyU98UrtMTvR4Kck/ft370pijz/2eNj2w1d+NImdfsbZYdtKsGf07w29MWx7aCI4zDeDQ3cXdW63MEZYOKAYxKOB0iXLlsXXh4c5t9CHgra1Wq2560vuhAXdzG6XdIGkNWY2Kunzki4ws3M1nQI7JX26g30EOoLcRm5OWNDd/cogfHMH+gJ0FbmN3JRu4jAAIEZBB4BMUNABIBMccLFA1OvpKPwP79sStv3ZyEgS+9Rn4rG7da97fRJrZTZKX7DEX5JqU9GBGuWf5bJ4BEvhW2nbyiyXYPbU0qJZLs095PTjBv2ySrX5B/H4UJgy4w4dADJBQQeATFDQASATFHQAyASDopJq9Xhw5MihQ0ms6GT7ZS0N8qQDNM9s357E7rvnnvD6j33iY0ls3RlnhW3nuhy/2tsfxnv7lwbRomE1BktLoXDwMf351QpGKithPL1+ydLlzXerYPAy+j0qukP14He8HuyRXnbcoQNAJijoAJAJCjoAZIKCDgCZoKADQCYW3SyXaKP7f77zn8K2D259MIm9+z3vDtte/ud/1nQfDr14MO3DHbcnseHhc8Prf//Nb01iRbNvWhPMGqjEKRLPcmE2S1lEk1HqBbO9vIWl/+GZE8EBF31LloTX14MHKH6utL+ttG3pRI+S4A4dADJBQQeATFDQASATJyzoZna6mT1gZtvM7Ekzu64RX21mW8zs6cbHVZ3vLtA+5DZy08yg6JSkz7r7I2Y2IOmnZrZF0icl3e/uN5rZBkkbJH2uc10tHvCYnJxMYseC2HTbY0nssUcfC9s+/JN03/HVq+Pf7Q988ANJrFKw7P6/7r8/7dehF5PYhZdcGl7fFw5IdkalGqdI1fu61ocOWjC53W3R71I0YWC6bRqzwm0ComAa7emPt5SI+lW0RL8WxKuF+7Q3GSu5E96hu/ted3+k8fmEpG2STpN0maTNjWabJX2oU50EOoHcRm5aeg/dzIYkvUXSQ5JOdfe90vQvhqRT2t05oFvIbeSg6YJuZisk3SXpend/oYXr1pvZiJmNjI+Pz6aPQEeR28hFUwXdzHo1nfC3uft3GuExM1vb+P5aSfuia919o7sPu/vw4OBgO/oMtA25jZw0M8vFJN0saZu73zTjW3dLuqrx+VWSvtf+7gGdQ24jN83Mcjlf0scl/dzMHm3EbpB0o6Q7zexqSc9K+nBnuvj/du3aFcY3feuWJDY2Nha2rU1NJbGdO38Ttj165EgSe3rbL8K2v/31U0ns2V/vDNt+/1/T+vDJqz+VxFaf8urw+m6qVONT1N17u9yTjlgwud1t4WySgoMkomkuRW0rQbwSbEvRVzTLJYgVPVetns7KccV5Waulv/dFB2eU2QkLurs/qOJNOi5qb3eA7iG3kRtWigJAJijoAJAJCjoAZKJU+6GvWhUvux9+e7o/+GM/+1nYdvfoaBI7eeWKsG3t2NEktm9fPN/4azf9TRosWFr8vkvfn8Te8KZzktjUVLpNgSRZwZYCkWgv68Ilz8HD7vnt/vhxg/Gk1510atP9wvwKB0VrBfuhR8vpCwYUwwHMaOl/b7x1RJSv9YItCaItAYq2B4m2NShqW2bcoQNAJijoAJAJCjoAZIKCDgCZoKADQCZKNctlxYp4Nsp7L7kkiV1w4YVh2yNHDiexw4cOhW0nJibStsH1ktQbLJFf+apXhW1ftfrk9Pq+dCl00WyWFia5yKKpK0XXBw+89tXrCppyL1Bm0bL3aCn9tKhtPEPELW1rlTSv+vriWS71YObJVEG/asFrmCqYERPPcgmblhq/lQCQCQo6AGSCgg4AmaCgA0AmSjUoWjRIGC0jLlpavGzFQFv7lLueahb7nuM40YBg4YBiCwOo0YYA0Z76/UuWNt2xerCX+fRzBW3rRdsXRP3Nb1SUO3QAyAQFHQAyQUEHgEw0c0j06Wb2gJltM7Mnzey6RvwLZrbbzB5t/Lm0890F2ofcRm6aGRSdkvRZd3/EzAYk/dTMtjS+91V3/3Lnugd0FLmNrDRzSPReSXsbn0+Y2TZJp3W6Y0CnLebcbuWQlOggiWiJviR5MFOmpyctMysG4tlmPb3pjBirxDNXFPTLgq0HJKmvJ30zolLJ7x3nll6RmQ1Jeoukhxqha83scTO7xczi44SAEiC3kYOmC7qZrZB0l6Tr3f0FSd+QdKakczV9l/OVguvWm9mImY2Mj8fHtwHzidxGLpoq6GbWq+mEv83dvyNJ7j7m7jWf3rbtm5LOi651943uPuzuw4ODg+3qN9AW5DZy0swsF5N0s6Rt7n7TjPjaGc0ul/RE+7sHdA65jdw0M8vlfEkfl/RzM3u0EbtB0pVmdq6m18/ulPTpjvQQ6JxFm9vLlqdnC/zRe9JzBSTp8WAA8/nnnwvb9venS/rf/PZ3JLHXnnlWeP1FH7w8ie361S/DtkePTSaxlQMrw7bnvHU4iS1dFp+vUGbNzHJ5UPGRCPe0vztA95DbyE1+83YAYJGioANAJijoAJAJCjoAZKJUB1wAaI8lS9PZKJ+45q/Ctoc/+ZdJ7OjRI2Hb3uBgmWhGTU9vfHDKNTd8MYkdm0xns0jxYRbValzSevvSfi36pf8AgIWLgg4AmaCgA0AmKOgAkAnzgn2NO/JkZuOSftP4co2k/V178u7hdc2f17r7vOySNSO3y/D3NFu5vrYyvK6mcrurBf1lT2w24u7pBgslx+ta3HL+e8r1teX0unjLBQAyQUEHgEzMZ0HfOI/P3Um8rsUt57+nXF9bNq9r3t5DBwC0F2+5AEAmul7QzewSM9tuZs+Y2YZuP387NU6E32dmT8yIrTazLWb2dONj6U6MN7PTzewBM9tmZk+a2XWNeOlfWyflktvkdfle20u6WtDNrCrpbyW9X9LZmj7q6+xu9qHNNkk6/tyuDZLud/ezJN3f+LpspiR91t3fKOkdkq5p/JxyeG0dkVlubxJ5XUrdvkM/T9Iz7r7D3Scl3SHpsi73oW3cfaukA8eFL5O0ufH5Zkkf6mqn2sDd97r7I43PJyRtk3SaMnhtHZRNbpPX5XttL+l2QT9N0q4ZX482Yjk51d33StMJJOmUee7PnJjZkKS3SHpImb22Nss9t7P62eea190u6NGBvEyzWaDMbIWkuyRd7+4vzHd/FjhyuyRyzutuF/RRSafP+Po1kvZ0uQ+dNmZmayWp8XHfPPdnVsysV9NJf5u7f6cRzuK1dUjuuZ3Fzz73vO52QX9Y0llmdoaZ9Um6QtLdXe5Dp90t6arG51dJ+t489mVWzMwk3Sxpm7vfNONbpX9tHZR7bpf+Z78Y8rrrC4vM7FJJX5NUlXSLu3+pqx1oIzO7XdIFmt6tbUzS5yX9i6Q7Ja2T9KykD7v78QNMC5qZ/bGk/5b0c0kvnfN1g6bfbyz1a+ukXHKbvC7fa3sJK0UBIBOsFAWATFDQASATFHQAyAQFHQAyQUEHgExQ0AEgExR0AMgEBR0AMvG/mLuIbggWcKkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize(29),  #将图像的短边缩放成29个像素，长边按短边比例缩放\n",
    "    transforms.RandomCrop(28),  #随机裁剪成28*28\n",
    "    ])\n",
    "def get_files(directory):\n",
    "    return [os.path.join(directory, f) for f in sorted(list(os.listdir(directory)))\n",
    "            if os.path.isfile(os.path.join(directory, f))]\n",
    "images = np.array([])\n",
    "file1 = get_files('C:/Users/15273/Desktop/figure')\n",
    "for i, item in enumerate(file1):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    image = transform(Image.open(item))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对图像进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 0.23844671249389648 s\n",
      "tensor([[ 1.2746, -2.7013,  1.3807, -0.2298, -1.8902,  2.2516,  2.0645, -0.2736,\n",
      "         -0.4326, -1.4464],\n",
      "        [-0.6153,  2.4787, -1.2158,  0.4734,  1.6364, -2.8482, -1.3431, -0.0835,\n",
      "          0.1115,  1.4012]], grad_fn=<AddmmBackward>)\n",
      "Predicted:  Sandal Trouser\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start=time.time()\n",
    "outputs = cnn(img)\n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print(outputs)\n",
    "classes = ('T-shirt', 'Trouser', 'Pollover', 'Dress',\n",
    "           'Coat', 'Sandal', 'Shirt','Sneaker', 'Bag', 'Ankle boot')\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
